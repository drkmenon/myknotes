---
title: "Data wrangling"
code-fold: true
---

Data wrangling is the process of making data ready for modelling. It is a tedious task and involves different logical steps.

```{mermaid}
flowchart LR
    Record --> Data --> Tidy\ndata --> Data\nanalysis
    
```

## Core Concepts 

1.  Always look directly into data and see how it look like

2.  Think how it should look like

3.  Think how to rearrange Information to achieve what we want 

4.  Make sure that what we does is doing what we want at every step. 

`r` is an excellent lower level language for data wrangling. The newer `data.table` make it even more faster and intuitive. `data. table` package in `r` which is faster than tidyverse. It is mainly used for data manipulation . As it retains native `data. frame`, all functions written for base r and tidyverse work with data. table. 

eg: `% > %` is called pipe function. It essentially means 'take whatever on the left side and make it the first argument for anything on the right Side'. It comes with tidyverse package. It can also be used with `data.table.` [^1]

[^1]: Now from r 4.1 onwards it is built in to base v as I \>

## data.table

`data.table` looks like `data.frame` superficially but it is lot more efficient, fast and allow numerous actions by simple commants.

```{mermaid}
flowchart TD
data.table --> i
i --> subsetting\nrow
data.table --> j
j --> subsetting\n&\ncalculating\nin\ncolumn
data.table --> by
by --> grouping
data.table --> useful\ncodes
useful\ncodes --> fread
useful\ncodes --> walrus

```

Old `data.frame` allow sub-setting rows and selecting columns. `data.table` which uses the extended syntax

$$
dt[i,j,by]
$$

allow lot more options.

### i,j and by

**`i`**`allows sub-setting and ordering row`

`dt[i]` allow multiple actions at row level of the data. Fundamentally this can be grouped in to sub-setting and ordering.

```{mermaid}
flowchart TD
i --> subsetting
i --> ordering


```

#### Sub-setting

Let us take an example of data set dt

``` r
library(data.table)
dt=fread("virtual.csv")
```

```{r}
library(data.table)
dt=fread("virtual.csv")
```

It contains a set of simple data comparing the performance of medical students in physical classes vs virtual classes and their perceptions. Assume, we want to see only the virtual class students. This can be easily achieved by sub-setting the type.class key in the data by "virtual" as shown below.

##### Select only virtual data

``` r
dtv=dt[type.class == "virtual"]
head(dtv)
```

```{r}
#| collapse: true
library(data.table)
dt=fread("virtual.csv")
dtv=dt[type.class == "virtual"]
head(dtv)
```

##### Select first 2 rows

If we want to select only first 2 rows[^2] , us the following code.

[^2]: note that, \[1:2,\] is not necessary. However \[1:2,\] shows the full picture.

    > Select first 2 rows and retain all the columns

``` r
dt2=dt[1:2]
dt2
```

```{r}
#| collapse: true
dt2=dt[1:2]
dt2
```

##### Ordering

Variables in the rows can be arranged in ascending or descending order by using the `order()` command as shown below.

``` r
dta=dt[order(posttest.score)] # use -posttest.score for descending order
dta
```

```{r}
#| collapse: true
dta=dt[order(posttest.score)] 
# use -posttest.score for descending order
dta
```

**`j`**`allows manipulations in the column`

dt\[,j\] allow selection, correction or mutation and calculations at column level.

```{mermaid}
flowchart TD
j --> Select
j --> Calculation
j --> Correct\ntypo
j --> Add\nor\nDelete\ncolumn

```

##### Select specific column[^3]

[^3]: dt\[,.(j)\]: blank followed by , denotes selecting all rows. "." denote "list". if "`."`is not used, data.table will give the output as vectors, instead of list.

Suppose we want to select only the necessary columns from our `dt` data set. We can do this by simple code as shown below.

``` r
dtc=dt[,.(idertifier,type.class,pretest.score,posttest.score,sex,likert.total)]
dtc
```

```{r}
#| collapse: true
dtc=dt[,.(idertifier,type.class,pretest.score,posttest.score,sex,likert.total)]
dtc
```

`data.table`‘s `j` can handle more than just *selecting columns* - it can handle *expressions*, i.e., *computing on columns*. 

##### Correct typos

In the dataset dt, we can see that the first key, identifier is misspelt as idertifier. We can correct it by following code

``` r
dtc=dt[,.(identifier=idertifier,type.class,pretest.score,posttest.score,sex,likert.total)]
dtc
```

```{r}
#| collapse: true
dtc=dt[,.(identifier=idertifier,type.class,pretest.score,posttest.score,sex,likert.total)]
dtc
```

##### Computing on columns

To calculate the mean post test score of the virtual class, following code can be used.

``` r
dtm=dt[type.class=="virtual",mean(posttest.score)]
dtm
```

```{r}
#| collapse: true
dtm=dt[type.class=="virtual",mean(posttest.score)]
dtm
```

##### Add or delete column

If we want to add mean post test score of virtual on to dtv.

To create or delete column, we use `:=`, called walrus operator.[^4]

[^4]: The walrus is a large pinniped marine mammal with discontinuous distribution about the North Pole in the Arctic Ocean and subarctic seas of the Northern Hemisphere. 

``` r
dtv[,mean.pt.score:=mean(posttest.score)]
dtv
```

```{r}
#| collapse: true
dtvm=dtv[,mean.pt.score:=mean(posttest.score)]
dtvm
```

To delete mean.pt.score,

``` r
dtv[,mean.pt.score:=NULL]
dtv
```

```{r}
#| collapse: true
dtvm[,mean.pt.score:=NULL]
dtvm
```

**`by`**`allow grouping`

```{mermaid}
flowchart LR
by --> grouping
```

### Aggregation

To group or aggregate data based on a `key`, the `by` operator can be used.

``` r
dtmn=dt[,mean(posttest.score), by=.(type.class)]
dtmn
```

```{r}
#| collapse: true
dtmn=dt[,mean(posttest.score), by=.(type.class)]
dtmn
```

`data.table` allow fast reading of data in to data table

### Adding data to r and reading it as data.table

``` r
library(data.table)
dt=fread("virtual.csv")
class(df)
str(dt)
```

```{r}
#| collapse: true
library(data.table)
dt=fread("virtual.csv")
class(df)
str(dt)
```

```{r}
#| collapse: true
vtable::vt(dt)
```

### How to look at data 

-   str(dt) 

    ```{r}
    #| collapse: true
    str(dt)
    ```

-   tables(dt)

-   summary(dt) 

-   vtable:: vt(dt)

### Stages of data wrangling

-   from record to data

-   data to tidy data

-   from tidy data to data analysis. 

### Process of wrangling

#### From records to data

::: callout-note
## Record

'Raw source', not in workable format. 
:::

```{mermaid}
flowchart TD
  A[multiple data tables] --> B(map)
  B --> C(rbind or rbindlist)
  C --> D[Stack one on top of another column]
  A --> E[merge]
  E --> F(attach raws to the side of raws)
```

### rbind

`rbind ( )` stacks data variables on top of one another from different data. tables. For this to work all the identifiers should be same on the different files that has to be compiled.

``` r
#| collapse: true
library(readxl)
Jan <- read_excel("Jan.xlsx")
jandt=as.data.table(Jan)
str(jandt)

Feb <- read_excel("Feb.xlsx")
febdt=as.data.table(Feb)
str(febdt)
```

```{r}
#| collapse: true
library(readxl)
Jan <- read_excel("Jan.xlsx")
jandt=as.data.table(Jan)
str(jandt)

Feb <- read_excel("Feb.xlsx")
febdt=as.data.table(Feb)
str(febdt)

```

``` r
#| collapse: true
rbind(jandt,febdt)
```

```{r}
#| collapse: true
rbind(jandt,febdt)
```

If data is in multiple excel files, use `map ( )` and `rbindlist ( )` to compile data.

`map ( )` comes with `purr` package.

We can merge the data tables using `merge ( )` function, if there is atleast one common identifier in each row.

```{r}
fdt=dt[,.(identifier=as.factor(idertifier),type.class=as.factor(type.class),posttest.score=as.numeric(posttest.score),pretest.score=as.numeric(pretest.score),total.likert=as.numeric(likert.total), sex=as.factor(sex))]
head(fdt)
```

```{r}
summary(fdt)
attach(fdt)
mean.score= fdt[,mean(posttest.score),by=type.class]
mean.pre.score= fdt[,mean(pretest.score),by=type.class]
mean.likert= fdt[,mean(total.likert),by=type.class]
mean.pre.score
mean.score
mean.likert
boxplot(posttest.score~type.class)
boxplot(pretest.score~type.class)
boxplot(total.likert~type.class)
boxplot(total.likert~sex)
```

```{r}
shapiro.test(posttest.score)
```

```{r}
t.test(posttest.score,pretest.score,var.equal=FALSE)
```

```{r}
t.test(posttest.score~type.class,var.equal=FALSE)
```

```{r}
shapiro.test(total.likert)
```

```{r}
t.test(total.likert~type.class, var.equal=FALSE)
```

### Interpretation

1.  **Data: `total.likert` by `type.class`**: The test is comparing the `total.likert` scores between two groups defined by `type.class` (physical and virtual).

2.  **t = 5.9265**: This is the t-statistic value. A larger absolute value indicates a greater difference between the groups.

3.  **df = 42.974**: This is the degrees of freedom, adjusted for Welch's t-test. It's not an integer because the test accounts for unequal variances.

4.  **p-value = 4.686e-07**: This is the p-value. A very small p-value (much less than 0.05) indicates strong evidence against the null hypothesis, suggesting a significant difference between the groups.

5.  **Alternative Hypothesis**: The test is checking if the true difference in means between the physical and virtual groups is not equal to 0.

6.  **95% Confidence Interval: 0.2172646 to 0.4414021**: This interval suggests that the true difference in means is between 0.217 and 0.441, with 95% confidence. This range does not include 0, supporting the conclusion that there is a significant difference between the groups.

7.  **Sample Estimates**:

    -   **Mean in group physical**: 3.833333

    -   **Mean in group virtual**: 3.504000

    These are the average `total.likert` scores for the physical and virtual groups, respectively. The physical group has a higher mean score.

### Summary

The results indicate a significant difference in `total.likert` scores between the physical and virtual groups, with the physical group having a higher average score. The very low p-value confirms the statistical significance of this difference. The confidence interval provides a range for the difference in means, further supporting the conclusion that the difference is meaningful and not due to random chance.

## readxl() and map()

```{r}
library(readxl)
library(purrr)

filelist=list.files(path="/Users/drkmenon/Sync/knotesquarto/Biomedical/Research Methodology",pattern='xlsx',full.names = TRUE)


process.file=function(df) {
   sales=df[1:5,4]
   employee=df[1:5,3]
   return(data.table(sales=sales,employee=employee))
}
   

compiled.data=filelist |>
  map(read_excel) |>
  map(process.file) |>
  rbindlist()

compiled.data

```
